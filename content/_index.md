---
# Leave the homepage title empty to use the site title
title: ''
date: 2024-03-04
type: landing

sections:
  - block: hero
    content:
      title: |-
        2024 Australian Survey Assessing AI Risks
      image:
        filename: sara_hero.png
      text: |-
        <br>
        A representative survey of Australian adults to understand public perceptions of AI risks and support for AI governance actions in Australia.
        <br>
      cta:
        label: Read a briefing of key results
        url: 'https://docs.google.com/document/d/1d0CRlBRLv3_a1fSye6cA6dzMjxtopjCcklc8irGPlDc/export?format=pdf&attachment=false'
        icon_pack: fas
        icon: star
      cta_alt:
        label: Full report
        url: 'mailto:alexander@aksaeri.com?subject=Send+SARA+report'
    design:
      background:
        color: #0C869B
  - block: markdown
    content:
      title: Key Insights
      text: |-
    
        A representative online Survey Assessing AI Risks (SARA) of 1,051 Australians in January-February 2024 investigated public perceptions of AI risks and support for AI governance actions.
    
        Australians are **most concerned about AI risks where AI acts unsafely** (e.g., acting in conflict with human values, failure of critical infrastructure), **is misused** (e.g., cyber attacks, biological weapons), or **displaces the jobs of humans**; they are least concerned about AI-assisted surveillance, or bias and discrimination in AI decision-making.
    
        Australians judge **“preventing dangerous and catastrophic outcomes from AI”** the **#1 priority for the Australian Government in AI**; 9 in 10 Australians support creating a new regulatory body for AI.
    
        The majority of Australians (8 in 10) support the statement that "mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war".
    design:
      columns: '2'
  - block: markdown
    content:
      title: Read the briefing
      text: |-
        ## [2024 Survey Assessing AI Risks - Summary Briefing]('files/2024 Survey Assessing AI Risks - Summary Briefing.pdf') (PDF)
        ## [2024 Survey Assessing AI Risks - Summary Briefing](https://docs.google.com/document/d/1d0CRlBRLv3_a1fSye6cA6dzMjxtopjCcklc8irGPlDc/edit) (Google doc)
    design:
      columns: '2'
  - block: markdown
    content:
      title: Australians are concerned about diverse risks from AI
      text: |-
        ![]('figures/SARA_risk_priority.png')
    design:
      columns: '1'
  - block: markdown
    content:
      title: Australians support regulatory and non-regulatory action to address risks from AI
      text: |-
        ![]('figures/SARA_policy_priority.png')
    design:
      columns: '1'
  - block: markdown
    content:
      title: About the Survey Assessing Risks from AI
      text: |-

        The development and use of AI technologies is accelerating. Across 2022 and 2023, new large-scale models have been announced monthly, and are achieving increasingly complex and general tasks9; this trend continues in 2024 with Google DeepMind Gemini, OpenAI Sora, and others. Experts in AI forecast that development of powerful AI models could lead to radical changes in wealth, health, and power on a scale comparable to the nuclear and industrial revolutions.

        Addressing the risks and harms from these changes requires effective AI governance: forming robust norms, policies, laws, processes and institutions to guide good decision-making about AI development, deployment and use. Effective governance is especially crucial for managing extreme or catastrophic risks from AI that are high impact and uncertain, such as harm from misuse, accident or loss of control.

        Understanding public beliefs and expectations about artificial intelligence (AI) risks and their possible responses is important for ensuring that the ethical, legal, and social implications of AI are addressed through effective governance. We conducted the *Survey Assessing Risks from AI* (SARA) to generate ‘evidence for action’, to help public and private actors make the decisions needed for safer AI development and use.
        
        This survey investigates public concerns about 14 different risks from AI, from AI being used to spread fake and harmful content online, to AI being used for the creation of biological and chemical weapons; public support for AI development and regulation; and priority governance actions to address risks from AI (with a focus on government action).
        
        We recruited 1,051 Australians through online representative quota sampling stratified by age, sex, and Australian state / territory. We also conducted multilevel regression with poststratification to construct more accurate population estimates based on 2021 Australian Census data.
    design:
      columns: '2'
  - block: contact
    id: contact
    content:
      title: Contact
      subtitle: ''
      text: |-
        Contact [Dr Alexander Saeri](mailto:a.saeri@uq.edu.au) to discuss the SARA project and its findings.
      appointment_url: 'https://calendar.app.google/sv3Sb5sjUxxTdssv8'
      autolink: true
      design:
        columns: '2'
---
