# Quick Reference: CSV Contents

## üìã One-Line Descriptions

| File | What It Shows | Use When... |
|------|--------------|-------------|
| **trust_measures.csv** | 14 measures ranked by how much they'd increase trust in AI (84-91%) | Showing what regulations would build public trust |
| **priority_risks.csv** | 15 AI risks ranked by public concern (53-96%) | Demonstrating which risks Australians care about most |
| **treaty_ban_agi.csv** | Support (57%) vs. oppose (43%) for banning superintelligent AI | Discussing international AI governance preferences |
| **regulation_concern.csv** | 74% worry govt won't go far enough vs. 26% worry it'll go too far | Showing public wants stronger regulation |
| **trust_tech_companies.csv** | Only 6% trust tech companies "a great deal" for AI safety | Highlighting distrust in industry self-regulation |
| **government_priority.csv** | 72% want risk management prioritized vs. 28% innovation | Demonstrating public preference for safety over speed |
| **ai_vs_airline.csv** | 94% want AI as safe or safer than commercial aviation | Showing extremely high public safety expectations |
| **worried_job_loss.csv** | 63% fairly/very worried about AI causing unemployment | Highlighting employment concerns |
| **worried_lose_control.csv** | 58% fairly/very worried about humans losing control of AI | Showing concern about existential risks |
| **ai_good_harm.csv** | 33% harm > good, 34% balanced, 33% good > harm | Demonstrating growing uncertainty (up from 20% neutral in 2024) |
| **regulation_pace.csv** | 83% think regulation is slower than AI development | Showing perception of regulatory lag |
| **willingness_to_pay.csv** | 49% would pay something annually to reduce catastrophic risk | Understanding economic preferences for safety |
| **media_ai_society.csv** | 80% want more coverage of AI's societal impact | Demonstrating demand for public discourse |
| **media_ai_regulation.csv** | 86% want more coverage of government AI regulation | Showing desire for regulatory transparency |
| **ai_usage_barriers.csv** | Privacy (57%), trust (32%), dislike of tech companies (31%) top barriers | Explaining why Australians avoid AI tools |

## üéØ Key Findings by Theme

### üîê TRUST DEFICIT
- **trust_tech_companies.csv**: 71% trust tech companies "not at all" or "not very much"
- **ai_usage_barriers.csv**: 32% don't use AI because they don't trust companies

### üìä REGULATION PREFERENCES
- **regulation_concern.csv**: 74% worry government won't regulate enough
- **regulation_pace.csv**: 83% think regulation is lagging technology
- **government_priority.csv**: 72% want risk management prioritized

### üéØ PRIORITY RISKS (Top 5)
From **priority_risks.csv**:
1. Data privacy (96%)
2. Cyber attacks (93%)
3. Deepfakes (92%)
4. Fake content (91%)
5. Weapons development (90%)

### ‚úÖ TRUST-BUILDING MEASURES (Top 5)
From **trust_measures.csv**:
1. Right to human review (91%)
2. Australian AI Safety Institute (90%)
3. Annual independent safety audits (89%)
4. External pre-deployment safety testing (89%)
5. Mandatory safety incident reporting (89%)

### ‚ö†Ô∏è RISK CONCERNS
- **worried_job_loss.csv**: 63% worried about unemployment
- **worried_lose_control.csv**: 58% worried about losing control
- **ai_vs_airline.csv**: 94% want aviation-grade safety (‚â•1 in 10 million)

### üì∞ MEDIA DEMAND
- **media_ai_society.csv**: 80% want more societal impact coverage
- **media_ai_regulation.csv**: 86% want more regulation coverage

## üèÜ Best Charts for Partner Presentations

### Executive Summary Slide
**File**: `government_priority.csv`
- Simple 2-bar chart
- Clear message: Public wants safety prioritized
- **Key stat**: 72% choose risk management over innovation

### Trust Gap Slide
**Files**:
1. `trust_tech_companies.csv` - Show low trust (only 6% trust "a great deal")
2. `trust_measures.csv` - Show what would help (top 5)

### Risk Priorities Slide
**File**: `priority_risks.csv`
- Top 10 as horizontal bars
- Shows broad consensus on priorities
- **Key stat**: 10 of 15 risks have 80%+ agreement

### Safety Expectations Slide
**File**: `ai_vs_airline.csv`
- Stacked or grouped column chart
- **Key stat**: 94% want AI as safe or safer than aviation
- Combine with expert risk assessments for impact

### What Would Increase Trust Slide
**File**: `trust_measures.csv`
- Top 7 measures as horizontal bars
- **Key stat**: All 14 measures above 84% agreement
- Shows clear path forward for policy

### Public Engagement Slide
**Files**:
1. `media_ai_society.csv` - 80% want more societal coverage
2. `media_ai_regulation.csv` - 86% want more regulation coverage
- Side-by-side column charts

### Barriers to Adoption Slide
**File**: `ai_usage_barriers.csv`
- Top 5 as horizontal bars
- **Key stats**: Privacy (57%), trust (32%), tech company dislike (31%)
- Explains adoption resistance

## üí° Presentation Tips

### For Policy Partners
Focus on:
- `regulation_concern.csv` - Shows political cover for action
- `trust_measures.csv` - Specific policies with public support
- `government_priority.csv` - Public mandate for risk management

### For Industry Partners
Focus on:
- `trust_tech_companies.csv` - The trust problem
- `ai_usage_barriers.csv` - Why adoption is low
- `trust_measures.csv` - How to rebuild trust

### For Safety/EA Community
Focus on:
- `worried_lose_control.csv` - Public concern about catastrophic risks
- `ai_vs_airline.csv` - Extremely low risk tolerance
- `treaty_ban_agi.csv` - Majority support for superintelligence ban

### For Media
Focus on:
- `ai_good_harm.csv` - Growing public uncertainty
- `media_ai_society.csv` & `media_ai_regulation.csv` - Public demand for coverage
- `priority_risks.csv` - What Australians care about

## üî¢ Quick Stats for Talks

**Trust Crisis:**
- 71% don't trust tech companies with AI safety
- 74% worry government won't regulate enough
- 83% think regulation is lagging

**High Safety Bar:**
- 94% want AI as safe or safer than aviation (‚â§1 in 10 million risk)
- Expert estimates: 1-10% catastrophic risk by 2100
- Gap: At least 60,000x difference

**Clear Policy Support:**
- 89% support AI Safety Institute
- 89% support pre-deployment safety testing
- 91% support right to human review

**Major Concerns:**
- 96% prioritize data privacy
- 63% worried about job loss
- 58% worried about losing control

**International Governance:**
- 57% support international ban on superintelligent AI
- 72% want government to prioritize risks over innovation

---

**Pro tip**: Pick 3-5 of these stats and repeat them throughout your presentation for maximum impact.
